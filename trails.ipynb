{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\NLP\\medi_bot_try\\.venv\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
    "from pinecone import Pinecone\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "\n",
    "def load_data(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                             glob = '*.pdf',\n",
    "                             loader_cls = PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data =  load_data(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in extracted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_result = embeddings.embed_query(\"Hello world\")\n",
    "# embedding_dimension = len(query_result)\n",
    "# print(query_result)\n",
    "# print(embedding_dimension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pc = Pinecone(api_key=\"b8153aea-8890-4efb-b1f5-506be0d53b43\")  # Intialize the pinecone\n",
    "index_name = \"test\"\n",
    "index = pc.Index(index_name)                                  # connect to index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"AIzaSyDgA0uI5oefVdp5KrOst26-owsa9KFFzvM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def store_embeddings(text_chunks, embeddings):\n",
    "#     for i, t in enumerate(text_chunks):\n",
    "#         # Create embeddings for the document\n",
    "#         vector = embeddings.embed_query(t.page_content)\n",
    "        \n",
    "#         # Generate a unique ID for each document\n",
    "#         doc_id = f\"doc_{i}\"\n",
    "\n",
    "#         metadata = {\n",
    "#             \"text\": t.page_content,\n",
    "\n",
    "#         }\n",
    "        \n",
    "#         # Upsert the vector with the generated ID\n",
    "#         index.upsert(\n",
    "#             vectors=[{\"id\": doc_id, \"values\": vector,\"metadata\":metadata}]\n",
    "#         )\n",
    "\n",
    "# # Store embeddings for the text chunks\n",
    "# docsearch = store_embeddings(text_chunks, embeddings)\n",
    "\n",
    "# print(\"Embeddings stored successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pinecone(query_text, index, embeddings, top_k=3):\n",
    "    # Generate embeddings for the query text\n",
    "    query_vector = embeddings.embed_query(query_text)\n",
    "    \n",
    "    # Query the index\n",
    "    query_response = index.query(\n",
    "        vector=query_vector,\n",
    "        top_k=top_k,\n",
    "        include_values=False,  # Set to True if you want to include the vector values in the results\n",
    "        include_metadata = True\n",
    "    )\n",
    "    \n",
    "    return query_response\n",
    "\n",
    "# Example query\n",
    "sample_query = \"What are allergies?\"\n",
    "query_response = query_pinecone(sample_query, index, embeddings)\n",
    "print(\"Query Results:\", query_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    google_api_key = \"AIzaSyDgA0uI5oefVdp5KrOst26-owsa9KFFzvM\"\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template=\"\"\"\n",
    "# Use the following pieces of information to answer the user's question.\n",
    "# If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "# Context: {context}\n",
    "# Question: {question}\n",
    "\n",
    "# Only return the helpful answer below and nothing else.\n",
    "# Helpful answer:\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings,pinecone_api_key= \"b8153aea-8890-4efb-b1f5-506be0d53b43\")\n",
    "\n",
    "# retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=\"\\nUse the following pieces of information to answer the user's question.\\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nContext: {context}\\n\\nOnly return the helpful answer below and nothing else.\\nHelpful answer:\\n\")), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain( retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_answer_chain.invoke({\"input\":\"what is acne?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Allergies are reactions to foreign substances called allergens. \\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what are allergies ?\"})\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allergies are reactions of the immune system to foreign substances called allergens, such as pollen, dust mites, or pet dander. \n",
      "\n",
      "Acne is a skin condition that occurs when pores or hair follicles become clogged with oil, dead skin cells, and bacteria. \n",
      "\n",
      "Exiting the query loop.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Prompt the user for a query\n",
    "    query = input(\"Enter your query (or type 'exit' to quit): \")\n",
    "    \n",
    "    # Check if the user wants to exit\n",
    "    if query.lower() == \"exit\":\n",
    "        print(\"Exiting the query loop.\")\n",
    "        break\n",
    "    \n",
    "    # Run the query\n",
    "    result= rag_chain.invoke({\"input\": query})\n",
    "    print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
